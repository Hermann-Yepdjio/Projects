

---------------------------------start loading data---------------------------------


Shape of train set:  (536, 15002)
Shape of test set:  (126, 15002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  3.2605674266815186  seconds---------------------

--------------------------------------start PCA:  100  features--------------------------------------------


Dataset's  new shape:  (662, 100)

-----------------------------------End PCA. Running time:  0.8256263732910156  seconds-------------------------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.019469261169433594  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7346989966555183
Accuracy for MLP with network configuration (550,): 0.7397260273972602

 Confusion Matrix: 
 [[66 38]
 [19 96]]

-----------------End MLP Classification. Running time:  0.2331695556640625  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 147 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 2/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 3/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 4/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 5/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 6/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 7/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 8/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 9/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 10/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 11/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 12/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 13/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 14/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 15/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 16/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 17/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 18/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 19/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 20/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 21/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 22/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 23/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 24/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 25/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 26/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 27/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 28/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 29/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 30/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 31/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 32/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 33/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 34/180

296/296 [==============================] - 0s 54us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 35/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 36/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 37/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 38/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 39/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 40/180

296/296 [==============================] - 0s 49us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 41/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 42/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 43/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 44/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 45/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 46/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 47/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 48/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 49/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 50/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 51/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 52/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 53/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 54/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 55/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 56/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 57/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 58/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 59/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 60/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 61/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 62/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 63/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 64/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 65/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 66/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 67/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 68/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 69/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 70/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 71/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 72/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 73/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 74/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 75/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 76/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 77/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 78/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 79/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 80/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 81/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 82/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 83/180

296/296 [==============================] - 0s 41us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 84/180

296/296 [==============================] - 0s 42us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 85/180

296/296 [==============================] - 0s 48us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 86/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 87/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 88/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 89/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 90/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 91/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 92/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 93/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 94/180

296/296 [==============================] - 0s 50us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 95/180

296/296 [==============================] - 0s 49us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 96/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 97/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 98/180

296/296 [==============================] - 0s 53us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 99/180

296/296 [==============================] - 0s 55us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 100/180

296/296 [==============================] - 0s 52us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 101/180

296/296 [==============================] - 0s 65us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 102/180

296/296 [==============================] - 0s 69us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 103/180

296/296 [==============================] - 0s 76us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 104/180

296/296 [==============================] - 0s 53us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 105/180

296/296 [==============================] - 0s 66us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 106/180

296/296 [==============================] - 0s 61us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 107/180

296/296 [==============================] - 0s 50us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 108/180

296/296 [==============================] - 0s 48us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 109/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 110/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 111/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 112/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 113/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 114/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 115/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 116/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 117/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 118/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 119/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 120/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 121/180

296/296 [==============================] - 0s 48us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 122/180

296/296 [==============================] - 0s 48us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 123/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 124/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 125/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 126/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 127/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 128/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 129/180

296/296 [==============================] - 0s 51us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 130/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 131/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 132/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 133/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 134/180

296/296 [==============================] - 0s 50us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 135/180

296/296 [==============================] - 0s 52us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 136/180

296/296 [==============================] - 0s 50us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 137/180

296/296 [==============================] - 0s 50us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 138/180

296/296 [==============================] - 0s 54us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 139/180

296/296 [==============================] - 0s 52us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 140/180

296/296 [==============================] - 0s 49us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 141/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 142/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 143/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 144/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 145/180

296/296 [==============================] - 0s 48us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 146/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 147/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 148/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 149/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 150/180

296/296 [==============================] - 0s 43us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 151/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 152/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 153/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 154/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 155/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 156/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 157/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 158/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 159/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 160/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 161/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 162/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 163/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 164/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 165/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 166/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 167/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 168/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 169/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 170/180

296/296 [==============================] - 0s 48us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 171/180

296/296 [==============================] - 0s 48us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 172/180

296/296 [==============================] - 0s 48us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 173/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 174/180

296/296 [==============================] - 0s 51us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 175/180

296/296 [==============================] - 0s 50us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 176/180

296/296 [==============================] - 0s 47us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 177/180

296/296 [==============================] - 0s 45us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 178/180

296/296 [==============================] - 0s 59us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 179/180

296/296 [==============================] - 0s 44us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
Epoch 180/180

296/296 [==============================] - 0s 46us/step - loss: 8.0251 - acc: 0.4966 - val_loss: 7.3807 - val_acc: 0.5306
AUC:  0.5105351170568562
Accuracy for MLP with network configuration (1000, 750, 1): 0.5342465753424658

 Confusion Matrix: 
 [[  4 100]
 [  2 113]]

-----------------End MLP Classification. Running time:  3.1397862434387207  seconds-------------------------



--------------------------------start SVM classification---------------------------------------


AUC:  0.7379180602006687
Accuracy for Support Vector Machine: 0.7397260273972602

 Confusion Matrix: 
 [[73 31]
 [26 89]]

--------------------End SVM classification. Running time:  1892.7664556503296  seconds---------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7557692307692309
Accuracy for Random Forest, n estimators 1100: 0.7579908675799086

 Confusion Matrix: 
 [[74 30]
 [23 92]]

--------------------End RF classification. Running time:  2.776905059814453  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.6596571906354515
Accuracy for linear perceptron with batch_size,  100000: 0.6575342465753424

 Confusion Matrix: 
 [[73 31]
 [44 71]]

--------------------End linear Perceptron classification. Running time:  0.003586292266845703  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 15002)
Shape of test set:  (126, 15002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  2.735734701156616  seconds---------------------

--------------------------------------start PCA:  200  features--------------------------------------------


Dataset's  new shape:  (662, 200)

-----------------------------------End PCA. Running time:  1.1876132488250732  seconds-------------------------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.022694826126098633  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7012959866220735
Accuracy for MLP with network configuration (550,): 0.7031963470319634

 Confusion Matrix: 
 [[69 35]
 [30 85]]

-----------------End MLP Classification. Running time:  0.17912936210632324  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 147 samples
Epoch 1/180

296/296 [==============================] - 0s 897us/step - loss: 10.8111 - acc: 0.3243 - val_loss: 8.5070 - val_acc: 0.4694
Epoch 2/180

296/296 [==============================] - 0s 49us/step - loss: 9.4256 - acc: 0.4122 - val_loss: 8.7263 - val_acc: 0.4558
Epoch 3/180

296/296 [==============================] - 0s 49us/step - loss: 9.3178 - acc: 0.4189 - val_loss: 8.2925 - val_acc: 0.4830
Epoch 4/180

296/296 [==============================] - 0s 47us/step - loss: 9.4812 - acc: 0.4088 - val_loss: 8.2937 - val_acc: 0.4830
Epoch 5/180

296/296 [==============================] - 0s 46us/step - loss: 9.2119 - acc: 0.4257 - val_loss: 8.2235 - val_acc: 0.4898
Epoch 6/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 7/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 8/180

296/296 [==============================] - 0s 44us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 9/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 10/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 11/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 12/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 13/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 14/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 15/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 16/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 17/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 18/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 19/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 20/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 21/180

296/296 [==============================] - 0s 52us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 22/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 23/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 24/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 25/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 26/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 27/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 28/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 29/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 30/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 31/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 32/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 33/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 34/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 35/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 36/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 37/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 38/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 39/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 40/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 41/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 42/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 43/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 44/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 45/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 46/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 47/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 48/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 49/180

296/296 [==============================] - 0s 51us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 50/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 51/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 52/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 53/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 54/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 55/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 56/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 57/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 58/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 59/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 60/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 61/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 62/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 63/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 64/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 65/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 66/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 67/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 68/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 69/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 70/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 71/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 72/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 73/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 74/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 75/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 76/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 77/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 78/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 79/180

296/296 [==============================] - 0s 44us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 80/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 81/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 82/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 83/180

296/296 [==============================] - 0s 50us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 84/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 85/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 86/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 87/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 88/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 89/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 90/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 91/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 92/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 93/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 94/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 95/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 96/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 97/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 98/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 99/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 100/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 101/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 102/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 103/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 104/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 105/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 106/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 107/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 108/180

296/296 [==============================] - 0s 50us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 109/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 110/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 111/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 112/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 113/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 114/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 115/180

296/296 [==============================] - 0s 52us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 116/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 117/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 118/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 119/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 120/180

296/296 [==============================] - 0s 60us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 121/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 122/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 123/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 124/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 125/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 126/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 127/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 128/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 129/180

296/296 [==============================] - 0s 44us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 130/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 131/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 132/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 133/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 134/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 135/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 136/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 137/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 138/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 139/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 140/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 141/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 142/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 143/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 144/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 145/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 146/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 147/180

296/296 [==============================] - 0s 51us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 148/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 149/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 150/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 151/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 152/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 153/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 154/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 155/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 156/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 157/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 158/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 159/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 160/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 161/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 162/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 163/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 164/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 165/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 166/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 167/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 168/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 169/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 170/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 171/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 172/180

296/296 [==============================] - 0s 46us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 173/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 174/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 175/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 176/180

296/296 [==============================] - 0s 45us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 177/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 178/180

296/296 [==============================] - 0s 47us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 179/180

296/296 [==============================] - 0s 49us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 180/180

296/296 [==============================] - 0s 48us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.4748858447488584

 Confusion Matrix: 
 [[104   0]
 [115   0]]

-----------------End MLP Classification. Running time:  3.1378235816955566  seconds-------------------------



--------------------------------start SVM classification---------------------------------------


AUC:  0.752341137123746
Accuracy for Support Vector Machine: 0.7534246575342466

 Confusion Matrix: 
 [[76 28]
 [26 89]]

--------------------End SVM classification. Running time:  1533.0832526683807  seconds---------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7649247491638796
Accuracy for Random Forest, n estimators 1100: 0.7671232876712328

 Confusion Matrix: 
 [[75 29]
 [22 93]]

--------------------End RF classification. Running time:  3.139859437942505  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.6596571906354515
Accuracy for linear perceptron with batch_size,  100000: 0.6575342465753424

 Confusion Matrix: 
 [[73 31]
 [44 71]]

--------------------End linear Perceptron classification. Running time:  0.0039136409759521484  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 15002)
Shape of test set:  (126, 15002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  2.6874165534973145  seconds---------------------

--------------------------------------start PCA:  300  features--------------------------------------------


Dataset's  new shape:  (662, 300)

-----------------------------------End PCA. Running time:  1.7534840106964111  seconds-------------------------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.04135298728942871  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7619565217391304
Accuracy for MLP with network configuration (550,): 0.7625570776255708

 Confusion Matrix: 
 [[78 26]
 [26 89]]

-----------------End MLP Classification. Running time:  0.4918363094329834  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 147 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 2/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 3/180

296/296 [==============================] - 0s 54us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 4/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 5/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 6/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 7/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 8/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 9/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 10/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 11/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 12/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 13/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 14/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 15/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 16/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 17/180

296/296 [==============================] - 0s 54us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 18/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 19/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 20/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 21/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 22/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 23/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 24/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 25/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 26/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 27/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 28/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 29/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 30/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 31/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 32/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 33/180

296/296 [==============================] - 0s 54us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 34/180

296/296 [==============================] - 0s 56us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 35/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 36/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 37/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 38/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 39/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 40/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 41/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 42/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 43/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 44/180

296/296 [==============================] - 0s 48us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 45/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 46/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 47/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 48/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 49/180

296/296 [==============================] - 0s 58us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 50/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 51/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 52/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 53/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 54/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 55/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 56/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 57/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 58/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 59/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 60/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 61/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 62/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 63/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 64/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 65/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 66/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 67/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 68/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 69/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 70/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 71/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 72/180

296/296 [==============================] - 0s 48us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 73/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 74/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 75/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 76/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 77/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 78/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 79/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 80/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 81/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 82/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 83/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 84/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 85/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 86/180

296/296 [==============================] - 0s 57us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 87/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 88/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 89/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 90/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 91/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 92/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 93/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 94/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 95/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 96/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 97/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 98/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 99/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 100/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 101/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 102/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 103/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 104/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 105/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 106/180

296/296 [==============================] - 0s 48us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 107/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 108/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 109/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 110/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 111/180

296/296 [==============================] - 0s 54us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 112/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 113/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 114/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 115/180

296/296 [==============================] - 0s 60us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 116/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 117/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 118/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 119/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 120/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 121/180

296/296 [==============================] - 0s 48us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 122/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 123/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 124/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 125/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 126/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 127/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 128/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 129/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 130/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 131/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 132/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 133/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 134/180

296/296 [==============================] - 0s 48us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 135/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 136/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 137/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 138/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 139/180

296/296 [==============================] - 0s 48us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 140/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 141/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 142/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 143/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 144/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 145/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 146/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 147/180

296/296 [==============================] - 0s 48us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 148/180

296/296 [==============================] - 0s 85us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 149/180

296/296 [==============================] - 0s 54us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 150/180

296/296 [==============================] - 0s 55us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 151/180

296/296 [==============================] - 0s 62us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 152/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 153/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 154/180

296/296 [==============================] - 0s 53us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 155/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 156/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 157/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 158/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 159/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 160/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 161/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 162/180

296/296 [==============================] - 0s 54us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 163/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 164/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 165/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 166/180

296/296 [==============================] - 0s 52us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 167/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 168/180

296/296 [==============================] - 0s 48us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 169/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 170/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 171/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 172/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 173/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 174/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 175/180

296/296 [==============================] - 0s 49us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 176/180

296/296 [==============================] - 0s 50us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 177/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 178/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 179/180

296/296 [==============================] - 0s 62us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
Epoch 180/180

296/296 [==============================] - 0s 51us/step - loss: 7.7791 - acc: 0.5169 - val_loss: 7.6525 - val_acc: 0.5238
AUC:  0.5654264214046822
Accuracy for MLP with network configuration (1000, 750, 1): 0.547945205479452

 Confusion Matrix: 
 [[95  9]
 [90 25]]

-----------------End MLP Classification. Running time:  3.4005157947540283  seconds-------------------------



--------------------------------start SVM classification---------------------------------------


AUC:  0.752341137123746
Accuracy for Support Vector Machine: 0.7534246575342466

 Confusion Matrix: 
 [[76 28]
 [26 89]]

--------------------End SVM classification. Running time:  1469.6886789798737  seconds---------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7649247491638796
Accuracy for Random Forest, n estimators 1100: 0.7671232876712328

 Confusion Matrix: 
 [[75 29]
 [22 93]]

--------------------End RF classification. Running time:  2.8150112628936768  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.6596571906354515
Accuracy for linear perceptron with batch_size,  100000: 0.6575342465753424

 Confusion Matrix: 
 [[73 31]
 [44 71]]

--------------------End linear Perceptron classification. Running time:  0.004129648208618164  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 15002)
Shape of test set:  (126, 15002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  2.6901297569274902  seconds---------------------

--------------------------------------start PCA:  400  features--------------------------------------------


Dataset's  new shape:  (662, 400)

-----------------------------------End PCA. Running time:  2.1419289112091064  seconds-------------------------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.050055503845214844  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.6940217391304349
Accuracy for MLP with network configuration (550,): 0.684931506849315

 Confusion Matrix: 
 [[91 13]
 [56 59]]

-----------------End MLP Classification. Running time:  0.2696876525878906  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 147 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 6.8152 - acc: 0.5743 - val_loss: 7.5656 - val_acc: 0.5306
Epoch 2/180

296/296 [==============================] - 0s 55us/step - loss: 7.8590 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 3/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 4/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 5/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 6/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 7/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 8/180

296/296 [==============================] - 0s 58us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 9/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 10/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 11/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 12/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 13/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 14/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 15/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 16/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 17/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 18/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 19/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 20/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 21/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 22/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 23/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 24/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 25/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 26/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 27/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 28/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 29/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 30/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 31/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 32/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 33/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 34/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 35/180

296/296 [==============================] - 0s 59us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 36/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 37/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 38/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 39/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 40/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 41/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 42/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 43/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 44/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 45/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 46/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 47/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 48/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 49/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 50/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 51/180

296/296 [==============================] - 0s 58us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 52/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 53/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 54/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 55/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 56/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 57/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 58/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 59/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 60/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 61/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 62/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 63/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 64/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 65/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 66/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 67/180

296/296 [==============================] - 0s 58us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 68/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 69/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 70/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 71/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 72/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 73/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 74/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 75/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 76/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 77/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 78/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 79/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 80/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 81/180

296/296 [==============================] - 0s 60us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 82/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 83/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 84/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 85/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 86/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 87/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 88/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 89/180

296/296 [==============================] - 0s 59us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 90/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 91/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 92/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 93/180

296/296 [==============================] - 0s 58us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 94/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 95/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 96/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 97/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 98/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 99/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 100/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 101/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 102/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 103/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 104/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 105/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 106/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 107/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 108/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 109/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 110/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 111/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 112/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 113/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 114/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 115/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 116/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 117/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 118/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 119/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 120/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 121/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 122/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 123/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 124/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 125/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 126/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 127/180

296/296 [==============================] - 0s 58us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 128/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 129/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 130/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 131/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 132/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 133/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 134/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 135/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 136/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 137/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 138/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 139/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 140/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 141/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 142/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 143/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 144/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 145/180

296/296 [==============================] - 0s 57us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 146/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 147/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 148/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 149/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 150/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 151/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 152/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 153/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 154/180

296/296 [==============================] - 0s 58us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 155/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 156/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 157/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 158/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 159/180

296/296 [==============================] - 0s 58us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 160/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 161/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 162/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 163/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 164/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 165/180

296/296 [==============================] - 0s 55us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 166/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 167/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 168/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 169/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 170/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 171/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 172/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 173/180

296/296 [==============================] - 0s 54us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 174/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 175/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 176/180

296/296 [==============================] - 0s 53us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 177/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 178/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 179/180

296/296 [==============================] - 0s 56us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 180/180

296/296 [==============================] - 0s 60us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.4748858447488584

 Confusion Matrix: 
 [[104   0]
 [115   0]]

-----------------End MLP Classification. Running time:  3.718818426132202  seconds-------------------------



--------------------------------start SVM classification---------------------------------------


AUC:  0.752341137123746
Accuracy for Support Vector Machine: 0.7534246575342466

 Confusion Matrix: 
 [[76 28]
 [26 89]]

--------------------End SVM classification. Running time:  1507.6319432258606  seconds---------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7605769230769232
Accuracy for Random Forest, n estimators 1100: 0.7625570776255708

 Confusion Matrix: 
 [[75 29]
 [23 92]]

--------------------End RF classification. Running time:  2.6871883869171143  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.6596571906354515
Accuracy for linear perceptron with batch_size,  100000: 0.6575342465753424

 Confusion Matrix: 
 [[73 31]
 [44 71]]

--------------------End linear Perceptron classification. Running time:  0.004231691360473633  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 15002)
Shape of test set:  (126, 15002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  2.713895797729492  seconds---------------------

--------------------------------------start PCA:  500  features--------------------------------------------


Dataset's  new shape:  (662, 500)

-----------------------------------End PCA. Running time:  2.5690877437591553  seconds-------------------------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.05941009521484375  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7489130434782609
Accuracy for MLP with network configuration (550,): 0.7488584474885844

 Confusion Matrix: 
 [[78 26]
 [29 86]]

-----------------End MLP Classification. Running time:  0.8705289363861084  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 147 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 7.1421 - acc: 0.5541 - val_loss: 7.4165 - val_acc: 0.5374
Epoch 2/180

296/296 [==============================] - 0s 61us/step - loss: 7.1433 - acc: 0.5541 - val_loss: 6.6574 - val_acc: 0.5850
Epoch 3/180

296/296 [==============================] - 0s 59us/step - loss: 6.9841 - acc: 0.5642 - val_loss: 6.9887 - val_acc: 0.5646
Epoch 4/180

296/296 [==============================] - 0s 60us/step - loss: 7.0038 - acc: 0.5608 - val_loss: 7.5202 - val_acc: 0.5306
Epoch 5/180

296/296 [==============================] - 0s 58us/step - loss: 7.0894 - acc: 0.5574 - val_loss: 7.5202 - val_acc: 0.5306
Epoch 6/180

296/296 [==============================] - 0s 58us/step - loss: 7.1427 - acc: 0.5541 - val_loss: 7.5202 - val_acc: 0.5306
Epoch 7/180

296/296 [==============================] - 0s 59us/step - loss: 7.1427 - acc: 0.5541 - val_loss: 7.6287 - val_acc: 0.5238
Epoch 8/180

296/296 [==============================] - 0s 62us/step - loss: 7.1092 - acc: 0.5541 - val_loss: 7.5202 - val_acc: 0.5306
Epoch 9/180

296/296 [==============================] - 0s 64us/step - loss: 7.1439 - acc: 0.5541 - val_loss: 7.7395 - val_acc: 0.5170
Epoch 10/180

296/296 [==============================] - 0s 58us/step - loss: 7.1989 - acc: 0.5507 - val_loss: 7.6311 - val_acc: 0.5238
Epoch 11/180

296/296 [==============================] - 0s 59us/step - loss: 7.1995 - acc: 0.5507 - val_loss: 7.6323 - val_acc: 0.5238
Epoch 12/180

296/296 [==============================] - 0s 58us/step - loss: 7.1995 - acc: 0.5507 - val_loss: 7.6323 - val_acc: 0.5238
Epoch 13/180

296/296 [==============================] - 0s 58us/step - loss: 7.2540 - acc: 0.5473 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 14/180

296/296 [==============================] - 0s 58us/step - loss: 7.2001 - acc: 0.5507 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 15/180

296/296 [==============================] - 0s 60us/step - loss: 7.1462 - acc: 0.5541 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 16/180

296/296 [==============================] - 0s 58us/step - loss: 7.2552 - acc: 0.5473 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 17/180

296/296 [==============================] - 0s 59us/step - loss: 7.3096 - acc: 0.5439 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 18/180

296/296 [==============================] - 0s 66us/step - loss: 7.3096 - acc: 0.5439 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 19/180

296/296 [==============================] - 0s 61us/step - loss: 7.3096 - acc: 0.5439 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 20/180

296/296 [==============================] - 0s 58us/step - loss: 7.3096 - acc: 0.5439 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 21/180

296/296 [==============================] - 0s 60us/step - loss: 7.3641 - acc: 0.5405 - val_loss: 7.7419 - val_acc: 0.5170
Epoch 22/180

296/296 [==============================] - 0s 58us/step - loss: 7.4185 - acc: 0.5372 - val_loss: 7.8515 - val_acc: 0.5102
Epoch 23/180

296/296 [==============================] - 0s 59us/step - loss: 7.5274 - acc: 0.5304 - val_loss: 7.8515 - val_acc: 0.5102
Epoch 24/180

296/296 [==============================] - 0s 59us/step - loss: 7.6363 - acc: 0.5236 - val_loss: 7.8515 - val_acc: 0.5102
Epoch 25/180

296/296 [==============================] - 0s 60us/step - loss: 7.6363 - acc: 0.5236 - val_loss: 7.8515 - val_acc: 0.5102
Epoch 26/180

296/296 [==============================] - 0s 59us/step - loss: 7.6363 - acc: 0.5236 - val_loss: 7.8515 - val_acc: 0.5102
Epoch 27/180

296/296 [==============================] - 0s 60us/step - loss: 7.6363 - acc: 0.5236 - val_loss: 7.8515 - val_acc: 0.5102
Epoch 28/180

296/296 [==============================] - 0s 61us/step - loss: 7.6363 - acc: 0.5236 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 29/180

296/296 [==============================] - 0s 60us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 30/180

296/296 [==============================] - 0s 58us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 31/180

296/296 [==============================] - 0s 57us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 32/180

296/296 [==============================] - 0s 59us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 33/180

296/296 [==============================] - 0s 58us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 34/180

296/296 [==============================] - 0s 62us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 35/180

296/296 [==============================] - 0s 58us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 36/180

296/296 [==============================] - 0s 59us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 37/180

296/296 [==============================] - 0s 59us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 38/180

296/296 [==============================] - 0s 61us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 39/180

296/296 [==============================] - 0s 58us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 40/180

296/296 [==============================] - 0s 59us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 41/180

296/296 [==============================] - 0s 60us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 42/180

296/296 [==============================] - 0s 58us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 43/180

296/296 [==============================] - 0s 58us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 44/180

296/296 [==============================] - 0s 57us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 45/180

296/296 [==============================] - 0s 56us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 46/180

296/296 [==============================] - 0s 62us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 47/180

296/296 [==============================] - 0s 59us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 48/180

296/296 [==============================] - 0s 58us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 49/180

296/296 [==============================] - 0s 59us/step - loss: 7.6908 - acc: 0.5203 - val_loss: 7.9612 - val_acc: 0.5034
Epoch 50/180

296/296 [==============================] - 0s 62us/step - loss: 7.6919 - acc: 0.5203 - val_loss: 7.8503 - val_acc: 0.5102
Epoch 51/180

296/296 [==============================] - 0s 57us/step - loss: 7.5274 - acc: 0.5304 - val_loss: 7.8503 - val_acc: 0.5102
Epoch 52/180

296/296 [==============================] - 0s 58us/step - loss: 7.3635 - acc: 0.5405 - val_loss: 7.6311 - val_acc: 0.5238
Epoch 53/180

296/296 [==============================] - 0s 59us/step - loss: 7.2546 - acc: 0.5473 - val_loss: 7.5214 - val_acc: 0.5306
Epoch 54/180

296/296 [==============================] - 0s 59us/step - loss: 7.1457 - acc: 0.5541 - val_loss: 7.6299 - val_acc: 0.5238
Epoch 55/180

296/296 [==============================] - 0s 60us/step - loss: 7.1457 - acc: 0.5541 - val_loss: 7.6299 - val_acc: 0.5238
Epoch 56/180

296/296 [==============================] - 0s 58us/step - loss: 7.1457 - acc: 0.5541 - val_loss: 7.6299 - val_acc: 0.5238
Epoch 57/180

296/296 [==============================] - 0s 57us/step - loss: 7.0912 - acc: 0.5574 - val_loss: 7.6299 - val_acc: 0.5238
Epoch 58/180

296/296 [==============================] - 0s 58us/step - loss: 7.0912 - acc: 0.5574 - val_loss: 7.6299 - val_acc: 0.5238
Epoch 59/180

296/296 [==============================] - 0s 58us/step - loss: 7.0367 - acc: 0.5608 - val_loss: 7.6299 - val_acc: 0.5238
Epoch 60/180

296/296 [==============================] - 0s 56us/step - loss: 6.9278 - acc: 0.5676 - val_loss: 7.6299 - val_acc: 0.5238
Epoch 61/180

296/296 [==============================] - 0s 60us/step - loss: 6.9278 - acc: 0.5676 - val_loss: 7.6299 - val_acc: 0.5238
Epoch 62/180

296/296 [==============================] - 0s 60us/step - loss: 6.9278 - acc: 0.5676 - val_loss: 7.5202 - val_acc: 0.5306
Epoch 63/180

296/296 [==============================] - 0s 61us/step - loss: 6.9259 - acc: 0.5676 - val_loss: 7.6287 - val_acc: 0.5238
Epoch 64/180

296/296 [==============================] - 0s 58us/step - loss: 6.9811 - acc: 0.5642 - val_loss: 7.5190 - val_acc: 0.5306
Epoch 65/180

296/296 [==============================] - 0s 64us/step - loss: 7.1421 - acc: 0.5541 - val_loss: 7.5190 - val_acc: 0.5306
Epoch 66/180

296/296 [==============================] - 0s 59us/step - loss: 7.1954 - acc: 0.5507 - val_loss: 7.2997 - val_acc: 0.5442
Epoch 67/180

296/296 [==============================] - 0s 58us/step - loss: 7.1403 - acc: 0.5541 - val_loss: 7.2985 - val_acc: 0.5442
Epoch 68/180

296/296 [==============================] - 0s 59us/step - loss: 7.0859 - acc: 0.5574 - val_loss: 7.2973 - val_acc: 0.5442
Epoch 69/180

296/296 [==============================] - 0s 60us/step - loss: 7.1936 - acc: 0.5507 - val_loss: 7.2973 - val_acc: 0.5442
Epoch 70/180

296/296 [==============================] - 0s 58us/step - loss: 7.1924 - acc: 0.5507 - val_loss: 7.2961 - val_acc: 0.5442
Epoch 71/180

296/296 [==============================] - 0s 60us/step - loss: 7.1924 - acc: 0.5507 - val_loss: 7.2961 - val_acc: 0.5442
Epoch 72/180

296/296 [==============================] - 0s 59us/step - loss: 7.1918 - acc: 0.5507 - val_loss: 7.2961 - val_acc: 0.5442
Epoch 73/180

296/296 [==============================] - 0s 61us/step - loss: 7.1918 - acc: 0.5507 - val_loss: 6.9672 - val_acc: 0.5646
Epoch 74/180

296/296 [==============================] - 0s 60us/step - loss: 7.2451 - acc: 0.5473 - val_loss: 6.9672 - val_acc: 0.5646
Epoch 75/180

296/296 [==============================] - 0s 60us/step - loss: 7.3528 - acc: 0.5405 - val_loss: 7.0756 - val_acc: 0.5578
Epoch 76/180

296/296 [==============================] - 0s 59us/step - loss: 7.3528 - acc: 0.5405 - val_loss: 7.2926 - val_acc: 0.5442
Epoch 77/180

296/296 [==============================] - 0s 59us/step - loss: 7.2983 - acc: 0.5439 - val_loss: 7.2926 - val_acc: 0.5442
Epoch 78/180

296/296 [==============================] - 0s 59us/step - loss: 7.3516 - acc: 0.5405 - val_loss: 7.2926 - val_acc: 0.5442
Epoch 79/180

296/296 [==============================] - 0s 60us/step - loss: 7.5045 - acc: 0.5304 - val_loss: 7.1877 - val_acc: 0.5510
Epoch 80/180

296/296 [==============================] - 0s 59us/step - loss: 7.1930 - acc: 0.5507 - val_loss: 7.4082 - val_acc: 0.5374
Epoch 81/180

296/296 [==============================] - 0s 58us/step - loss: 7.2480 - acc: 0.5473 - val_loss: 7.2997 - val_acc: 0.5442
Epoch 82/180

296/296 [==============================] - 0s 59us/step - loss: 7.1948 - acc: 0.5507 - val_loss: 7.2997 - val_acc: 0.5442
Epoch 83/180

296/296 [==============================] - 0s 59us/step - loss: 7.1948 - acc: 0.5507 - val_loss: 7.4094 - val_acc: 0.5374
Epoch 84/180

296/296 [==============================] - 0s 58us/step - loss: 7.1409 - acc: 0.5541 - val_loss: 7.5190 - val_acc: 0.5306
Epoch 85/180

296/296 [==============================] - 0s 60us/step - loss: 7.0876 - acc: 0.5574 - val_loss: 7.5190 - val_acc: 0.5306
Epoch 86/180

296/296 [==============================] - 0s 58us/step - loss: 7.0338 - acc: 0.5608 - val_loss: 7.3021 - val_acc: 0.5442
Epoch 87/180

296/296 [==============================] - 0s 58us/step - loss: 6.9799 - acc: 0.5642 - val_loss: 7.4118 - val_acc: 0.5374
Epoch 88/180

296/296 [==============================] - 0s 57us/step - loss: 6.9799 - acc: 0.5642 - val_loss: 7.5214 - val_acc: 0.5306
Epoch 89/180

296/296 [==============================] - 0s 58us/step - loss: 6.9805 - acc: 0.5642 - val_loss: 7.4130 - val_acc: 0.5374
Epoch 90/180

296/296 [==============================] - 0s 59us/step - loss: 6.9267 - acc: 0.5676 - val_loss: 7.5226 - val_acc: 0.5306
Epoch 91/180

296/296 [==============================] - 0s 63us/step - loss: 6.9267 - acc: 0.5676 - val_loss: 7.5226 - val_acc: 0.5306
Epoch 92/180

296/296 [==============================] - 0s 60us/step - loss: 6.9267 - acc: 0.5676 - val_loss: 7.5226 - val_acc: 0.5306
Epoch 93/180

296/296 [==============================] - 0s 58us/step - loss: 6.9267 - acc: 0.5676 - val_loss: 7.5226 - val_acc: 0.5306
Epoch 94/180

296/296 [==============================] - 0s 61us/step - loss: 6.9267 - acc: 0.5676 - val_loss: 7.6323 - val_acc: 0.5238
Epoch 95/180

296/296 [==============================] - 0s 58us/step - loss: 6.9267 - acc: 0.5676 - val_loss: 7.6323 - val_acc: 0.5238
Epoch 96/180

296/296 [==============================] - 0s 58us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.6323 - val_acc: 0.5238
Epoch 97/180

296/296 [==============================] - 0s 59us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 98/180

296/296 [==============================] - 0s 59us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 99/180

296/296 [==============================] - 0s 58us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 100/180

296/296 [==============================] - 0s 58us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 101/180

296/296 [==============================] - 0s 62us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 102/180

296/296 [==============================] - 0s 59us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 103/180

296/296 [==============================] - 0s 63us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 104/180

296/296 [==============================] - 0s 64us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 105/180

296/296 [==============================] - 0s 62us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 106/180

296/296 [==============================] - 0s 67us/step - loss: 6.8728 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 107/180

296/296 [==============================] - 0s 64us/step - loss: 6.8214 - acc: 0.5709 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 108/180

296/296 [==============================] - 0s 63us/step - loss: 6.8189 - acc: 0.5743 - val_loss: 7.4153 - val_acc: 0.5374
Epoch 109/180

296/296 [==============================] - 0s 68us/step - loss: 6.8189 - acc: 0.5743 - val_loss: 7.3069 - val_acc: 0.5442
Epoch 110/180

296/296 [==============================] - 0s 59us/step - loss: 6.8189 - acc: 0.5743 - val_loss: 7.3069 - val_acc: 0.5442
Epoch 111/180

296/296 [==============================] - 0s 56us/step - loss: 6.8189 - acc: 0.5743 - val_loss: 7.3069 - val_acc: 0.5442
Epoch 112/180

296/296 [==============================] - 0s 58us/step - loss: 6.7651 - acc: 0.5777 - val_loss: 7.3069 - val_acc: 0.5442
Epoch 113/180

296/296 [==============================] - 0s 59us/step - loss: 6.7651 - acc: 0.5777 - val_loss: 7.3069 - val_acc: 0.5442
Epoch 114/180

296/296 [==============================] - 0s 60us/step - loss: 6.6574 - acc: 0.5845 - val_loss: 7.3069 - val_acc: 0.5442
Epoch 115/180

296/296 [==============================] - 0s 60us/step - loss: 6.6035 - acc: 0.5878 - val_loss: 7.4165 - val_acc: 0.5374
Epoch 116/180

296/296 [==============================] - 0s 59us/step - loss: 6.6579 - acc: 0.5845 - val_loss: 7.4165 - val_acc: 0.5374
Epoch 117/180

296/296 [==============================] - 0s 59us/step - loss: 6.6041 - acc: 0.5878 - val_loss: 7.4165 - val_acc: 0.5374
Epoch 118/180

296/296 [==============================] - 0s 59us/step - loss: 6.6041 - acc: 0.5878 - val_loss: 7.4165 - val_acc: 0.5374
Epoch 119/180

296/296 [==============================] - 0s 59us/step - loss: 6.5502 - acc: 0.5912 - val_loss: 7.4165 - val_acc: 0.5374
Epoch 120/180

296/296 [==============================] - 0s 59us/step - loss: 6.5502 - acc: 0.5912 - val_loss: 7.5262 - val_acc: 0.5306
Epoch 121/180

296/296 [==============================] - 0s 59us/step - loss: 6.4964 - acc: 0.5946 - val_loss: 7.5262 - val_acc: 0.5306
Epoch 122/180

296/296 [==============================] - 0s 57us/step - loss: 6.4964 - acc: 0.5946 - val_loss: 7.4177 - val_acc: 0.5374
Epoch 123/180

296/296 [==============================] - 0s 59us/step - loss: 6.4964 - acc: 0.5946 - val_loss: 7.4177 - val_acc: 0.5374
Epoch 124/180

296/296 [==============================] - 0s 57us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.3093 - val_acc: 0.5442
Epoch 125/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4189 - val_acc: 0.5374
Epoch 126/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4189 - val_acc: 0.5374
Epoch 127/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.3105 - val_acc: 0.5442
Epoch 128/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.3105 - val_acc: 0.5442
Epoch 129/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 130/180

296/296 [==============================] - 0s 61us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 131/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 132/180

296/296 [==============================] - 0s 57us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 133/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 134/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 135/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 136/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 137/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 138/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 139/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 140/180

296/296 [==============================] - 0s 61us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 141/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 142/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 143/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 144/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 145/180

296/296 [==============================] - 0s 61us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 146/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 147/180

296/296 [==============================] - 0s 62us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 148/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 149/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 150/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 151/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 152/180

296/296 [==============================] - 0s 62us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 153/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 154/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 155/180

296/296 [==============================] - 0s 57us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 156/180

296/296 [==============================] - 0s 62us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 157/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 158/180

296/296 [==============================] - 0s 62us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 159/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 160/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 161/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 162/180

296/296 [==============================] - 0s 65us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 163/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 164/180

296/296 [==============================] - 0s 62us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 165/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 166/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 167/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 168/180

296/296 [==============================] - 0s 62us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 169/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 170/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 171/180

296/296 [==============================] - 0s 60us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 172/180

296/296 [==============================] - 0s 61us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 173/180

296/296 [==============================] - 0s 63us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 174/180

296/296 [==============================] - 0s 58us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 175/180

296/296 [==============================] - 0s 64us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 176/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 177/180

296/296 [==============================] - 0s 64us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 178/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 179/180

296/296 [==============================] - 0s 61us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
Epoch 180/180

296/296 [==============================] - 0s 59us/step - loss: 6.5508 - acc: 0.5912 - val_loss: 7.4201 - val_acc: 0.5374
AUC:  0.5358277591973244
Accuracy for MLP with network configuration (1000, 750, 1): 0.5342465753424658

 Confusion Matrix: 
 [[59 45]
 [57 58]]

-----------------End MLP Classification. Running time:  3.966331720352173  seconds-------------------------



--------------------------------start SVM classification---------------------------------------


AUC:  0.752341137123746
Accuracy for Support Vector Machine: 0.7534246575342466

 Confusion Matrix: 
 [[76 28]
 [26 89]]

--------------------End SVM classification. Running time:  1498.777755022049  seconds---------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7697324414715719
Accuracy for Random Forest, n estimators 1100: 0.771689497716895

 Confusion Matrix: 
 [[76 28]
 [22 93]]

--------------------End RF classification. Running time:  2.548321485519409  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.6596571906354515
Accuracy for linear perceptron with batch_size,  100000: 0.6575342465753424

 Confusion Matrix: 
 [[73 31]
 [44 71]]

--------------------End linear Perceptron classification. Running time:  0.004386425018310547  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 15002)
Shape of test set:  (126, 15002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  2.681448221206665  seconds---------------------

--------------------------------------start PCA:  600  features--------------------------------------------


Dataset's  new shape:  (662, 600)

-----------------------------------End PCA. Running time:  0.774439811706543  seconds-------------------------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.06885743141174316  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7296822742474917
Accuracy for MLP with network configuration (550,): 0.730593607305936

 Confusion Matrix: 
 [[74 30]
 [29 86]]

-----------------End MLP Classification. Running time:  0.8395392894744873  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 147 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 7.2439 - acc: 0.5473 - val_loss: 7.4106 - val_acc: 0.5374
Epoch 2/180

296/296 [==============================] - 0s 65us/step - loss: 7.3546 - acc: 0.5405 - val_loss: 7.3045 - val_acc: 0.5442
Epoch 3/180

296/296 [==============================] - 0s 61us/step - loss: 7.2480 - acc: 0.5473 - val_loss: 7.5238 - val_acc: 0.5306
Epoch 4/180

296/296 [==============================] - 0s 63us/step - loss: 7.3031 - acc: 0.5439 - val_loss: 7.7431 - val_acc: 0.5170
Epoch 5/180

296/296 [==============================] - 0s 62us/step - loss: 7.3575 - acc: 0.5405 - val_loss: 7.7431 - val_acc: 0.5170
Epoch 6/180

296/296 [==============================] - 0s 65us/step - loss: 7.5110 - acc: 0.5304 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 7/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 8/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 9/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 10/180

296/296 [==============================] - 0s 69us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 11/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 12/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 13/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 14/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 15/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 16/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 17/180

296/296 [==============================] - 0s 67us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 18/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 19/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 20/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 21/180

296/296 [==============================] - 0s 69us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 22/180

296/296 [==============================] - 0s 71us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 23/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 24/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 25/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 26/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 27/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 28/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 29/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 30/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 31/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 32/180

296/296 [==============================] - 0s 73us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 33/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 34/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 35/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 36/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 37/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 38/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 39/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 40/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 41/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 42/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 43/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 44/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 45/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 46/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 47/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 48/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 49/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 50/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 51/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 52/180

296/296 [==============================] - 0s 69us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 53/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 54/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 55/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 56/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 57/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 58/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 59/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 60/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 61/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 62/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 63/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 64/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 65/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 66/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 67/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 68/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 69/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 70/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 71/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 72/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 73/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 74/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 75/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 76/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 77/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 78/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 79/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 80/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 81/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 82/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 83/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 84/180

296/296 [==============================] - 0s 72us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 85/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 86/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 87/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 88/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 89/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 90/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 91/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 92/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 93/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 94/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 95/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 96/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 97/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 98/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 99/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 100/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 101/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 102/180

296/296 [==============================] - 0s 77us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 103/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 104/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 105/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 106/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 107/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 108/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 109/180

296/296 [==============================] - 0s 67us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 110/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 111/180

296/296 [==============================] - 0s 70us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 112/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 113/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 114/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 115/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 116/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 117/180

296/296 [==============================] - 0s 67us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 118/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 119/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 120/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 121/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 122/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 123/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 124/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 125/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 126/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 127/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 128/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 129/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 130/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 131/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 132/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 133/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 134/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 135/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 136/180

296/296 [==============================] - 0s 71us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 137/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 138/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 139/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 140/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 141/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 142/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 143/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 144/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 145/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 146/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 147/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 148/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 149/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 150/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 151/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 152/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 153/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 154/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 155/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 156/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 157/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 158/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 159/180

296/296 [==============================] - 0s 66us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 160/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 161/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 162/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 163/180

296/296 [==============================] - 0s 68us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 164/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 165/180

296/296 [==============================] - 0s 67us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 166/180

296/296 [==============================] - 0s 67us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 167/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 168/180

296/296 [==============================] - 0s 61us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 169/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 170/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 171/180

296/296 [==============================] - 0s 65us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 172/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 173/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 174/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 175/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 176/180

296/296 [==============================] - 0s 64us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 177/180

296/296 [==============================] - 0s 67us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 178/180

296/296 [==============================] - 0s 62us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 179/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
Epoch 180/180

296/296 [==============================] - 0s 63us/step - loss: 7.8957 - acc: 0.5101 - val_loss: 8.3332 - val_acc: 0.4830
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.4748858447488584

 Confusion Matrix: 
 [[104   0]
 [115   0]]

-----------------End MLP Classification. Running time:  4.257359981536865  seconds-------------------------



--------------------------------start SVM classification---------------------------------------


AUC:  0.752341137123746
Accuracy for Support Vector Machine: 0.7534246575342466

 Confusion Matrix: 
 [[76 28]
 [26 89]]

--------------------End SVM classification. Running time:  1501.795242547989  seconds---------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7649247491638796
Accuracy for Random Forest, n estimators 1100: 0.7671232876712328

 Confusion Matrix: 
 [[75 29]
 [22 93]]

--------------------End RF classification. Running time:  2.403353214263916  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.6596571906354515
Accuracy for linear perceptron with batch_size,  100000: 0.6575342465753424

 Confusion Matrix: 
 [[73 31]
 [44 71]]

--------------------End linear Perceptron classification. Running time:  0.00450444221496582  seconds---------------------

