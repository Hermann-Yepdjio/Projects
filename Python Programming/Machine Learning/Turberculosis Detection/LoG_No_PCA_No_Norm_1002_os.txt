

---------------------------------start loading data---------------------------------


Shape of train set:  (536, 1002)
Shape of test set:  (126, 1002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  0.6296265125274658  seconds---------------------



--------------------------------start oversampling training set---------------------------------------


The positive set is being oversampled...

Shape of new train set:  (444, 1002)
Shape of new train targets:  (444,)

-------------- End oversampling training set. Running time:  0.0018475055694580078  seconds---------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.06034660339355469  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.80685618729097
Accuracy for MLP with network configuration (550,): 0.7990867579908676

 Confusion Matrix: 
 [[100   4]
 [ 40  75]]

-----------------End MLP Classification. Running time:  0.7469489574432373  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 297 samples, validate on 147 samples
Epoch 1/180

297/297 [==============================] - 0s 1ms/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 2/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 3/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 4/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 5/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 6/180

297/297 [==============================] - 0s 85us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 7/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 8/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 9/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 10/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 11/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 12/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 13/180

297/297 [==============================] - 0s 74us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 14/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 15/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 16/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 17/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 18/180

297/297 [==============================] - 0s 84us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 19/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 20/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 21/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 22/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 23/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 24/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 25/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 26/180

297/297 [==============================] - 0s 75us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 27/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 28/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 29/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 30/180

297/297 [==============================] - 0s 87us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 31/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 32/180

297/297 [==============================] - 0s 84us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 33/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 34/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 35/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 36/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 37/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 38/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 39/180

297/297 [==============================] - 0s 75us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 40/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 41/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 42/180

297/297 [==============================] - 0s 74us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 43/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 44/180

297/297 [==============================] - 0s 85us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 45/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 46/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 47/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 48/180

297/297 [==============================] - 0s 88us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 49/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 50/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 51/180

297/297 [==============================] - 0s 75us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 52/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 53/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 54/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 55/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 56/180

297/297 [==============================] - 0s 83us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 57/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 58/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 59/180

297/297 [==============================] - 0s 84us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 60/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 61/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 62/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 63/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 64/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 65/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 66/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 67/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 68/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 69/180

297/297 [==============================] - 0s 89us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 70/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 71/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 72/180

297/297 [==============================] - 0s 89us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 73/180

297/297 [==============================] - 0s 85us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 74/180

297/297 [==============================] - 0s 86us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 75/180

297/297 [==============================] - 0s 87us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 76/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 77/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 78/180

297/297 [==============================] - 0s 75us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 79/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 80/180

297/297 [==============================] - 0s 83us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 81/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 82/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 83/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 84/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 85/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 86/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 87/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 88/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 89/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 90/180

297/297 [==============================] - 0s 84us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 91/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 92/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 93/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 94/180

297/297 [==============================] - 0s 86us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 95/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 96/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 97/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 98/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 99/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 100/180

297/297 [==============================] - 0s 75us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 101/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 102/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 103/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 104/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 105/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 106/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 107/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 108/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 109/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 110/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 111/180

297/297 [==============================] - 0s 87us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 112/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 113/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 114/180

297/297 [==============================] - 0s 83us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 115/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 116/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 117/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 118/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 119/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 120/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 121/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 122/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 123/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 124/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 125/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 126/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 127/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 128/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 129/180

297/297 [==============================] - 0s 74us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 130/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 131/180

297/297 [==============================] - 0s 75us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 132/180

297/297 [==============================] - 0s 95us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 133/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 134/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 135/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 136/180

297/297 [==============================] - 0s 73us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 137/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 138/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 139/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 140/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 141/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 142/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 143/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 144/180

297/297 [==============================] - 0s 75us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 145/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 146/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 147/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 148/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 149/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 150/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 151/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 152/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 153/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 154/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 155/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 156/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 157/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 158/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 159/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 160/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 161/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 162/180

297/297 [==============================] - 0s 81us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 163/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 164/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 165/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 166/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 167/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 168/180

297/297 [==============================] - 0s 74us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 169/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 170/180

297/297 [==============================] - 0s 83us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 171/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 172/180

297/297 [==============================] - 0s 75us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 173/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 174/180

297/297 [==============================] - 0s 77us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 175/180

297/297 [==============================] - 0s 82us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 176/180

297/297 [==============================] - 0s 80us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 177/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 178/180

297/297 [==============================] - 0s 78us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 179/180

297/297 [==============================] - 0s 76us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
Epoch 180/180

297/297 [==============================] - 0s 79us/step - loss: 8.0862 - acc: 0.4983 - val_loss: 8.0042 - val_acc: 0.5034
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.4748858447488584

 Confusion Matrix: 
 [[104   0]
 [115   0]]

-----------------End MLP Classification. Running time:  4.971452951431274  seconds-------------------------



--------------------------------start SVM classification---------------------------------------


AUC:  0.8489548494983278
Accuracy for Support Vector Machine: 0.8447488584474886

 Confusion Matrix: 
 [[97  7]
 [27 88]]

--------------------End SVM classification. Running time:  20.030145168304443  seconds---------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.8480351170568561
Accuracy for Random Forest, n estimators 1100: 0.8447488584474886

 Confusion Matrix: 
 [[95  9]
 [25 90]]

--------------------End RF classification. Running time:  1.7730634212493896  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.5
Accuracy for linear perceptron with batch_size,  100000: 0.5251141552511416

 Confusion Matrix: 
 [[  0 104]
 [  0 115]]

--------------------End linear Perceptron classification. Running time:  0.0066411495208740234  seconds---------------------

