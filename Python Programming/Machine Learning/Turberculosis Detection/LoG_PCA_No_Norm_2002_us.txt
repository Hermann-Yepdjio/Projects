

---------------------------------start loading data---------------------------------


Shape of train set:  (536, 2002)
Shape of test set:  (126, 2002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  0.7174355983734131  seconds---------------------

--------------------------------------start PCA:  100  features--------------------------------------------


Dataset's  new shape:  (662, 100)

-----------------------------------End PCA. Running time:  0.13074088096618652  seconds-------------------------------------



---------------------------------start undersampling training set--------------------------------------


The negative set is being undersampled...

Shape of new train set:  (442, 100)
Shape of new train targets:  (442,)

--------------End undersampling training set. Running time:  0.0011138916015625  seconds---------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.026196956634521484  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7958612040133779
Accuracy for MLP with network configuration (550,): 0.7899543378995434

 Confusion Matrix: 
 [[95  9]
 [37 78]]

-----------------End MLP Classification. Running time:  0.2438211441040039  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 146 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 2/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 3/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 4/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 5/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 6/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 7/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 8/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 9/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 10/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 11/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 12/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 13/180

296/296 [==============================] - 0s 50us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 14/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 15/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 16/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 17/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 18/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 19/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 20/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 21/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 22/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 23/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 24/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 25/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 26/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 27/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 28/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 29/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 30/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 31/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 32/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 33/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 34/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 35/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 36/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 37/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 38/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 39/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 40/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 41/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 42/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 43/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 44/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 45/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 46/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 47/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 48/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 49/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 50/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 51/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 52/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 53/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 54/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 55/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 56/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 57/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 58/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 59/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 60/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 61/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 62/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 63/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 64/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 65/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 66/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 67/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 68/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 69/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 70/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 71/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 72/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 73/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 74/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 75/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 76/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 77/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 78/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 79/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 80/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 81/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 82/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 83/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 84/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 85/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 86/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 87/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 88/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 89/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 90/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 91/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 92/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 93/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 94/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 95/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 96/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 97/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 98/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 99/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 100/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 101/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 102/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 103/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 104/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 105/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 106/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 107/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 108/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 109/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 110/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 111/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 112/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 113/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 114/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 115/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 116/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 117/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 118/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 119/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 120/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 121/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 122/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 123/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 124/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 125/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 126/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 127/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 128/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 129/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 130/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 131/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 132/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 133/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 134/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 135/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 136/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 137/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 138/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 139/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 140/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 141/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 142/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 143/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 144/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 145/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 146/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 147/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 148/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 149/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 150/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 151/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 152/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 153/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 154/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 155/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 156/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 157/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 158/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 159/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 160/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 161/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 162/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 163/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 164/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 165/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 166/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 167/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 168/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 169/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 170/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 171/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 172/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 173/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 174/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 175/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 176/180

296/296 [==============================] - 0s 43us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 177/180

296/296 [==============================] - 0s 41us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 178/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 179/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 180/180

296/296 [==============================] - 0s 42us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.4748858447488584

 Confusion Matrix: 
 [[104   0]
 [115   0]]

-----------------End MLP Classification. Running time:  3.008960247039795  seconds-------------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7557692307692309
Accuracy for Random Forest, n estimators 1100: 0.7579908675799086

 Confusion Matrix: 
 [[74 30]
 [23 92]]

--------------------End RF classification. Running time:  2.7808754444122314  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.7267140468227424
Accuracy for linear perceptron with batch_size,  100000: 0.726027397260274

 Confusion Matrix: 
 [[77 27]
 [33 82]]

--------------------End linear Perceptron classification. Running time:  0.0036690235137939453  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 2002)
Shape of test set:  (126, 2002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  0.5488474369049072  seconds---------------------

--------------------------------------start PCA:  200  features--------------------------------------------


Dataset's  new shape:  (662, 200)

-----------------------------------End PCA. Running time:  0.15101003646850586  seconds-------------------------------------



---------------------------------start undersampling training set--------------------------------------


The negative set is being undersampled...

Shape of new train set:  (442, 200)
Shape of new train targets:  (442,)

--------------End undersampling training set. Running time:  0.0007472038269042969  seconds---------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.027364730834960938  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7408862876254181
Accuracy for MLP with network configuration (550,): 0.7442922374429224

 Confusion Matrix: 
 [[70 34]
 [22 93]]

-----------------End MLP Classification. Running time:  0.43652915954589844  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 146 samples
Epoch 1/180

296/296 [==============================] - 0s 912us/step - loss: 6.7082 - acc: 0.5811 - val_loss: 6.1558 - val_acc: 0.6164
Epoch 2/180

296/296 [==============================] - 0s 46us/step - loss: 5.9625 - acc: 0.6284 - val_loss: 5.6098 - val_acc: 0.6507
Epoch 3/180

296/296 [==============================] - 0s 48us/step - loss: 5.9673 - acc: 0.6284 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 4/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 5/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 6/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 7/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 8/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 9/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 10/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 11/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 12/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 13/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 14/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 15/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 16/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 17/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 18/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 19/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 20/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 21/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 22/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 23/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 24/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 25/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 26/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 27/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 28/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 29/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 30/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 31/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 32/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 33/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 34/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 35/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 36/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 37/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 38/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 39/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 40/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 41/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 42/180

296/296 [==============================] - 0s 51us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 43/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 44/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 45/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 46/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 47/180

296/296 [==============================] - 0s 51us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 48/180

296/296 [==============================] - 0s 51us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 49/180

296/296 [==============================] - 0s 50us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 50/180

296/296 [==============================] - 0s 64us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 51/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 52/180

296/296 [==============================] - 0s 51us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 53/180

296/296 [==============================] - 0s 50us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 54/180

296/296 [==============================] - 0s 50us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 55/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 56/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 57/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 58/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 59/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 60/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 61/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 62/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 63/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 64/180

296/296 [==============================] - 0s 50us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 65/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 66/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 67/180

296/296 [==============================] - 0s 50us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 68/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 69/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 70/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 71/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 72/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 73/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 74/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 75/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 76/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 77/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 78/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 79/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 80/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 81/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 82/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 83/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 84/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 85/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 86/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 87/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 88/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 89/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 90/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 91/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 92/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 93/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 94/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 95/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 96/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 97/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 98/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 99/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 100/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 101/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 102/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 103/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 104/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 105/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 106/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 107/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 108/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 109/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 110/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 111/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 112/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 113/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 114/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 115/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 116/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 117/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 118/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 119/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 120/180

296/296 [==============================] - 0s 68us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 121/180

296/296 [==============================] - 0s 52us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 122/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 123/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 124/180

296/296 [==============================] - 0s 52us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 125/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 126/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 127/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 128/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 129/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 130/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 131/180

296/296 [==============================] - 0s 44us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 132/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 133/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 134/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 135/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 136/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 137/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 138/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 139/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 140/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 141/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 142/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 143/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 144/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 145/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 146/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 147/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 148/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 149/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 150/180

296/296 [==============================] - 0s 63us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 151/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 152/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 153/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 154/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 155/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 156/180

296/296 [==============================] - 0s 48us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 157/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 158/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 159/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 160/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 161/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 162/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 163/180

296/296 [==============================] - 0s 50us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 164/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 165/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 166/180

296/296 [==============================] - 0s 45us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 167/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 168/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 169/180

296/296 [==============================] - 0s 46us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 170/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 171/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 172/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 173/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 174/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 175/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 176/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 177/180

296/296 [==============================] - 0s 51us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 178/180

296/296 [==============================] - 0s 49us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 179/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 180/180

296/296 [==============================] - 0s 47us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.4748858447488584

 Confusion Matrix: 
 [[104   0]
 [115   0]]

-----------------End MLP Classification. Running time:  3.175241231918335  seconds-------------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7601170568561874
Accuracy for Random Forest, n estimators 1100: 0.7625570776255708

 Confusion Matrix: 
 [[74 30]
 [22 93]]

--------------------End RF classification. Running time:  3.1382436752319336  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.7267140468227424
Accuracy for linear perceptron with batch_size,  100000: 0.726027397260274

 Confusion Matrix: 
 [[77 27]
 [33 82]]

--------------------End linear Perceptron classification. Running time:  0.003705739974975586  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 2002)
Shape of test set:  (126, 2002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  0.5534038543701172  seconds---------------------

--------------------------------------start PCA:  300  features--------------------------------------------


Dataset's  new shape:  (662, 300)

-----------------------------------End PCA. Running time:  0.23962950706481934  seconds-------------------------------------



---------------------------------start undersampling training set--------------------------------------


The negative set is being undersampled...

Shape of new train set:  (442, 300)
Shape of new train targets:  (442,)

--------------End undersampling training set. Running time:  0.0016684532165527344  seconds---------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.08175516128540039  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.8004180602006689
Accuracy for MLP with network configuration (550,): 0.7990867579908676

 Confusion Matrix: 
 [[86 18]
 [26 89]]

-----------------End MLP Classification. Running time:  0.46814727783203125  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 146 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 2/180

296/296 [==============================] - 0s 53us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 3/180

296/296 [==============================] - 0s 58us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 4/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 5/180

296/296 [==============================] - 0s 52us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 6/180

296/296 [==============================] - 0s 56us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 7/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 8/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 9/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 10/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 11/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 12/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 13/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 14/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 15/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 16/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 17/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 18/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 19/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 20/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 21/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 22/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 23/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 24/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 25/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 26/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 27/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 28/180

296/296 [==============================] - 0s 54us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 29/180

296/296 [==============================] - 0s 57us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 30/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 31/180

296/296 [==============================] - 0s 53us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 32/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 33/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 34/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 35/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 36/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 37/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 38/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 39/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 40/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 41/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 42/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 43/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 44/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 45/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 46/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 47/180

296/296 [==============================] - 0s 48us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 48/180

296/296 [==============================] - 0s 48us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 49/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 50/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 51/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 52/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 53/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 54/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 55/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 56/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 57/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 58/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 59/180

296/296 [==============================] - 0s 53us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 60/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 61/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 62/180

296/296 [==============================] - 0s 53us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 63/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 64/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 65/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 66/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 67/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 68/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 69/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 70/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 71/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 72/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 73/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 74/180

296/296 [==============================] - 0s 54us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 75/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 76/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 77/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 78/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 79/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 80/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 81/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 82/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 83/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 84/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 85/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 86/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 87/180

296/296 [==============================] - 0s 53us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 88/180

296/296 [==============================] - 0s 48us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 89/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 90/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 91/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 92/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 93/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 94/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 95/180

296/296 [==============================] - 0s 59us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 96/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 97/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 98/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 99/180

296/296 [==============================] - 0s 53us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 100/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 101/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 102/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 103/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 104/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 105/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 106/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 107/180

296/296 [==============================] - 0s 52us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 108/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 109/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 110/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 111/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 112/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 113/180

296/296 [==============================] - 0s 56us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 114/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 115/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 116/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 117/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 118/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 119/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 120/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 121/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 122/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 123/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 124/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 125/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 126/180

296/296 [==============================] - 0s 53us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 127/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 128/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 129/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 130/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 131/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 132/180

296/296 [==============================] - 0s 60us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 133/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 134/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 135/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 136/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 137/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 138/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 139/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 140/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 141/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 142/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 143/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 144/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 145/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 146/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 147/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 148/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 149/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 150/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 151/180

296/296 [==============================] - 0s 49us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 152/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 153/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 154/180

296/296 [==============================] - 0s 53us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 155/180

296/296 [==============================] - 0s 55us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 156/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 157/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 158/180

296/296 [==============================] - 0s 53us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 159/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 160/180

296/296 [==============================] - 0s 62us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 161/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 162/180

296/296 [==============================] - 0s 52us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 163/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 164/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 165/180

296/296 [==============================] - 0s 48us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 166/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 167/180

296/296 [==============================] - 0s 51us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 168/180

296/296 [==============================] - 0s 48us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 169/180

296/296 [==============================] - 0s 51us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 170/180

296/296 [==============================] - 0s 53us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 171/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 172/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 173/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 174/180

296/296 [==============================] - 0s 53us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 175/180

296/296 [==============================] - 0s 50us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 176/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 177/180

296/296 [==============================] - 0s 53us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 178/180

296/296 [==============================] - 0s 49us/step - loss: 8.9976 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 179/180

296/296 [==============================] - 0s 50us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
Epoch 180/180

296/296 [==============================] - 0s 52us/step - loss: 8.9977 - acc: 0.4392 - val_loss: 9.0129 - val_acc: 0.4384
AUC:  0.46350334448160535
Accuracy for MLP with network configuration (1000, 750, 1): 0.4611872146118721

 Confusion Matrix: 
 [[53 51]
 [67 48]]

-----------------End MLP Classification. Running time:  3.393139123916626  seconds-------------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7601170568561874
Accuracy for Random Forest, n estimators 1100: 0.7625570776255708

 Confusion Matrix: 
 [[74 30]
 [22 93]]

--------------------End RF classification. Running time:  2.8398640155792236  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.7267140468227424
Accuracy for linear perceptron with batch_size,  100000: 0.726027397260274

 Confusion Matrix: 
 [[77 27]
 [33 82]]

--------------------End linear Perceptron classification. Running time:  0.012213945388793945  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 2002)
Shape of test set:  (126, 2002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  0.5391433238983154  seconds---------------------

--------------------------------------start PCA:  400  features--------------------------------------------


Dataset's  new shape:  (662, 400)

-----------------------------------End PCA. Running time:  0.2919926643371582  seconds-------------------------------------



---------------------------------start undersampling training set--------------------------------------


The negative set is being undersampled...

Shape of new train set:  (442, 400)
Shape of new train targets:  (442,)

--------------End undersampling training set. Running time:  0.0008387565612792969  seconds---------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.04031705856323242  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7429765886287626
Accuracy for MLP with network configuration (550,): 0.7397260273972602

 Confusion Matrix: 
 [[84 20]
 [37 78]]

-----------------End MLP Classification. Running time:  0.28299570083618164  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 146 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 9.1054 - acc: 0.4324 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 2/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 3/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 4/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 5/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 6/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 7/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 8/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 9/180

296/296 [==============================] - 0s 59us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 10/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 11/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 12/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 13/180

296/296 [==============================] - 0s 52us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 14/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 15/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 16/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 17/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 18/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 19/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 20/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 21/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 22/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 23/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 24/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 25/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 26/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 27/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 28/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 29/180

296/296 [==============================] - 0s 58us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 30/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 31/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 32/180

296/296 [==============================] - 0s 62us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 33/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 34/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 35/180

296/296 [==============================] - 0s 58us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 36/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 37/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 38/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 39/180

296/296 [==============================] - 0s 58us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 40/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 41/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 42/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 43/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 44/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 45/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 46/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 47/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 48/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 49/180

296/296 [==============================] - 0s 52us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 50/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 51/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 52/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 53/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 54/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 55/180

296/296 [==============================] - 0s 52us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 56/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 57/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 58/180

296/296 [==============================] - 0s 58us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 59/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 60/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 61/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 62/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 63/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 64/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 65/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 66/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 67/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 68/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 69/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 70/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 71/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 72/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 73/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 74/180

296/296 [==============================] - 0s 52us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 75/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 76/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 77/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 78/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 79/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 80/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 81/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 82/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 83/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 84/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 85/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 86/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 87/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 88/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 89/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 90/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 91/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 92/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 93/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 94/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 95/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 96/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 97/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 98/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 99/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 100/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 101/180

296/296 [==============================] - 0s 62us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 102/180

296/296 [==============================] - 0s 59us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 103/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 104/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 105/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 106/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 107/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 108/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 109/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 110/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 111/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 112/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 113/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 114/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 115/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 116/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 117/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 118/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 119/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 120/180

296/296 [==============================] - 0s 58us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 121/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 122/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 123/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 124/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 125/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 126/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 127/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 128/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 129/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 130/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 131/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 132/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 133/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 134/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 135/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 136/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 137/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 138/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 139/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 140/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 141/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 142/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 143/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 144/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 145/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 146/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 147/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 148/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 149/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 150/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 151/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 152/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 153/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 154/180

296/296 [==============================] - 0s 67us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 155/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 156/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 157/180

296/296 [==============================] - 0s 61us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 158/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 159/180

296/296 [==============================] - 0s 63us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 160/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 161/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 162/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 163/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 164/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 165/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 166/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 167/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 168/180

296/296 [==============================] - 0s 58us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 169/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 170/180

296/296 [==============================] - 0s 53us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 171/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 172/180

296/296 [==============================] - 0s 56us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 173/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 174/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 175/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 176/180

296/296 [==============================] - 0s 58us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 177/180

296/296 [==============================] - 0s 55us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 178/180

296/296 [==============================] - 0s 54us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 179/180

296/296 [==============================] - 0s 59us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
Epoch 180/180

296/296 [==============================] - 0s 57us/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.4748858447488584

 Confusion Matrix: 
 [[104   0]
 [115   0]]

-----------------End MLP Classification. Running time:  3.716231346130371  seconds-------------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7649247491638796
Accuracy for Random Forest, n estimators 1100: 0.7671232876712328

 Confusion Matrix: 
 [[75 29]
 [22 93]]

--------------------End RF classification. Running time:  2.68656849861145  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.7267140468227424
Accuracy for linear perceptron with batch_size,  100000: 0.726027397260274

 Confusion Matrix: 
 [[77 27]
 [33 82]]

--------------------End linear Perceptron classification. Running time:  0.004304409027099609  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 2002)
Shape of test set:  (126, 2002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  0.5385980606079102  seconds---------------------

--------------------------------------start PCA:  500  features--------------------------------------------


Dataset's  new shape:  (662, 500)

-----------------------------------End PCA. Running time:  0.4969644546508789  seconds-------------------------------------



---------------------------------start undersampling training set--------------------------------------


The negative set is being undersampled...

Shape of new train set:  (442, 500)
Shape of new train targets:  (442,)

--------------End undersampling training set. Running time:  0.0008556842803955078  seconds---------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.08615970611572266  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7557692307692309
Accuracy for MLP with network configuration (550,): 0.7579908675799086

 Confusion Matrix: 
 [[74 30]
 [23 92]]

-----------------End MLP Classification. Running time:  0.41092753410339355  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 146 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 8.7108 - acc: 0.4561 - val_loss: 8.8905 - val_acc: 0.4452
Epoch 2/180

296/296 [==============================] - 0s 60us/step - loss: 9.1461 - acc: 0.4291 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 3/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 4/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 5/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 6/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 7/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 8/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 9/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 10/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 11/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 12/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 13/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 14/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 15/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 16/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 17/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 18/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 19/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 20/180

296/296 [==============================] - 0s 56us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 21/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 22/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 23/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 24/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 25/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 26/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 27/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 28/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 29/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 30/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 31/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 32/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 33/180

296/296 [==============================] - 0s 69us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 34/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 35/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 36/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 37/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 38/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 39/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 40/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 41/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 42/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 43/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 44/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 45/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 46/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 47/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 48/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 49/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 50/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 51/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 52/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 53/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 54/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 55/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 56/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 57/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 58/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 59/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 60/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 61/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 62/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 63/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 64/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 65/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 66/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 67/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 68/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 69/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 70/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 71/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 72/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 73/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 74/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 75/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 76/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 77/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 78/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 79/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 80/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 81/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 82/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 83/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 84/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 85/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 86/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 87/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 88/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 89/180

296/296 [==============================] - 0s 66us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 90/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 91/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 92/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 93/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 94/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 95/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 96/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 97/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 98/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 99/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 100/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 101/180

296/296 [==============================] - 0s 56us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 102/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 103/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 104/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 105/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 106/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 107/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 108/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 109/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 110/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 111/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 112/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 113/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 114/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 115/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 116/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 117/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 118/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 119/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 120/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 121/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 122/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 123/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 124/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 125/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 126/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 127/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 128/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 129/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 130/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 131/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 132/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 133/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 134/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 135/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 136/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 137/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 138/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 139/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 140/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 141/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 142/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 143/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 144/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 145/180

296/296 [==============================] - 0s 67us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 146/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 147/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 148/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 149/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 150/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 151/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 152/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 153/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 154/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 155/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 156/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 157/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 158/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 159/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 160/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 161/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 162/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 163/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 164/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 165/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 166/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 167/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 168/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 169/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 170/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 171/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 172/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 173/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 174/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 175/180

296/296 [==============================] - 0s 59us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 176/180

296/296 [==============================] - 0s 58us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 177/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 178/180

296/296 [==============================] - 0s 57us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 179/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 180/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.5251141552511416

 Confusion Matrix: 
 [[  0 104]
 [  0 115]]

-----------------End MLP Classification. Running time:  3.9666576385498047  seconds-------------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7610367892976588
Accuracy for Random Forest, n estimators 1100: 0.7625570776255708

 Confusion Matrix: 
 [[76 28]
 [24 91]]

--------------------End RF classification. Running time:  2.5639853477478027  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.7267140468227424
Accuracy for linear perceptron with batch_size,  100000: 0.726027397260274

 Confusion Matrix: 
 [[77 27]
 [33 82]]

--------------------End linear Perceptron classification. Running time:  0.004370212554931641  seconds---------------------



---------------------------------start loading data---------------------------------


Shape of train set:  (536, 2002)
Shape of test set:  (126, 2002)
Shape of train targets:  (536,)
Shape of test targets:  (126,)

--------------End loading data.  Running time:  0.5550050735473633  seconds---------------------

--------------------------------------start PCA:  600  features--------------------------------------------


Dataset's  new shape:  (662, 600)

-----------------------------------End PCA. Running time:  0.14179134368896484  seconds-------------------------------------



---------------------------------start undersampling training set--------------------------------------


The negative set is being undersampled...

Shape of new train set:  (442, 600)
Shape of new train targets:  (442,)

--------------End undersampling training set. Running time:  0.0027022361755371094  seconds---------------------



--------------------------------start KNN classification---------------------------------------


AUC:  0.7498327759197323
Accuracy for KNN with  12 :  0.7488584474885844

 Confusion Matrix: 
 [[80 24]
 [31 84]]

----------------End KNN classification. Running time:  0.07213163375854492  seconds------------------------



--------------------------------start MLP classification---------------------------------------


AUC:  0.7665133779264213
Accuracy for MLP with network configuration (550,): 0.771689497716895

 Confusion Matrix: 
 [[ 69  35]
 [ 15 100]]

-----------------End MLP Classification. Running time:  0.6700584888458252  seconds-------------------------



--------------------------------start MLP classification---------------------------------------


here
Train on 296 samples, validate on 146 samples
Epoch 1/180

296/296 [==============================] - 0s 1ms/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 2/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 3/180

296/296 [==============================] - 0s 67us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 4/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 5/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 6/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 7/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 8/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 9/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 10/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 11/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 12/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 13/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 14/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 15/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 16/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 17/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 18/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 19/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 20/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 21/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 22/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 23/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 24/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 25/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 26/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 27/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 28/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 29/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 30/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 31/180

296/296 [==============================] - 0s 68us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 32/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 33/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 34/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 35/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 36/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 37/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 38/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 39/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 40/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 41/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 42/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 43/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 44/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 45/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 46/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 47/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 48/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 49/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 50/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 51/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 52/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 53/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 54/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 55/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 56/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 57/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 58/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 59/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 60/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 61/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 62/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 63/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 64/180

296/296 [==============================] - 0s 75us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 65/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 66/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 67/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 68/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 69/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 70/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 71/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 72/180

296/296 [==============================] - 0s 67us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 73/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 74/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 75/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 76/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 77/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 78/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 79/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 80/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 81/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 82/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 83/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 84/180

296/296 [==============================] - 0s 68us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 85/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 86/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 87/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 88/180

296/296 [==============================] - 0s 67us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 89/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 90/180

296/296 [==============================] - 0s 71us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 91/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 92/180

296/296 [==============================] - 0s 68us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 93/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 94/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 95/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 96/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 97/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 98/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 99/180

296/296 [==============================] - 0s 66us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 100/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 101/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 102/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 103/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 104/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 105/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 106/180

296/296 [==============================] - 0s 70us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 107/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 108/180

296/296 [==============================] - 0s 68us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 109/180

296/296 [==============================] - 0s 66us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 110/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 111/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 112/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 113/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 114/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 115/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 116/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 117/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 118/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 119/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 120/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 121/180

296/296 [==============================] - 0s 68us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 122/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 123/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 124/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 125/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 126/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 127/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 128/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 129/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 130/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 131/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 132/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 133/180

296/296 [==============================] - 0s 75us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 134/180

296/296 [==============================] - 0s 69us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 135/180

296/296 [==============================] - 0s 67us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 136/180

296/296 [==============================] - 0s 72us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 137/180

296/296 [==============================] - 0s 67us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 138/180

296/296 [==============================] - 0s 67us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 139/180

296/296 [==============================] - 0s 68us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 140/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 141/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 142/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 143/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 144/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 145/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 146/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 147/180

296/296 [==============================] - 0s 67us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 148/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 149/180

296/296 [==============================] - 0s 60us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 150/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 151/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 152/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 153/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 154/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 155/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 156/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 157/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 158/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 159/180

296/296 [==============================] - 0s 69us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 160/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 161/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 162/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 163/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 164/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 165/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 166/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 167/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 168/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 169/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 170/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 171/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 172/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 173/180

296/296 [==============================] - 0s 64us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 174/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 175/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 176/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 177/180

296/296 [==============================] - 0s 63us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 178/180

296/296 [==============================] - 0s 65us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 179/180

296/296 [==============================] - 0s 61us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
Epoch 180/180

296/296 [==============================] - 0s 62us/step - loss: 7.9712 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000
AUC:  0.5
Accuracy for MLP with network configuration (1000, 750, 1): 0.5251141552511416

 Confusion Matrix: 
 [[  0 104]
 [  0 115]]

-----------------End MLP Classification. Running time:  4.2173991203308105  seconds-------------------------



--------------------------------start RF classification---------------------------------------


AUC:  0.7649247491638796
Accuracy for Random Forest, n estimators 1100: 0.7671232876712328

 Confusion Matrix: 
 [[75 29]
 [22 93]]

--------------------End RF classification. Running time:  2.4190282821655273  seconds---------------------



--------------------------------start linear Perceptron classification---------------------------------------



The model is being  partially fitted with batch #1  out of  1...

AUC:  0.7267140468227424
Accuracy for linear perceptron with batch_size,  100000: 0.726027397260274

 Confusion Matrix: 
 [[77 27]
 [33 82]]

--------------------End linear Perceptron classification. Running time:  0.004452705383300781  seconds---------------------

